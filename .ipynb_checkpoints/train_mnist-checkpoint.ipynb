{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import *\n",
    "from utils import mnist_reader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_list = [\n",
    "        'train-images-idx3-ubyte.gz',\n",
    "        'train-labels-idx1-ubyte.gz',\n",
    "        't10k-images-idx3-ubyte.gz',\n",
    "        't10k-labels-idx1-ubyte.gz'\n",
    "    ]\n",
    "\n",
    "dataset_dir = '/Users/komei0727/workspace/robot_intelligence/data/mnist'\n",
    "\n",
    "dataset = mnist_reader.load_mnist(dl_list, dataset_dir)\n",
    "train_img,train_label,test_img,test_label = dataset\n",
    "\n",
    "#画素値を0~1の間の値に変換\n",
    "train_img = train_img / 255\n",
    "test_img = test_img / 255\n",
    "train_img = train_img.astype(np.float32)\n",
    "#ラベルをone-hot表現で表す\n",
    "train_label = [int(x) for x in train_label]\n",
    "train_label_one_hot = np.identity(10)[train_label].astype(np.float32)\n",
    "test_label = [int(x) for x in test_label]\n",
    "test_label_one_hot = np.identity(10)[test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_rate = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_img)):\n",
    "    for j in range(len(train_img[0])):\n",
    "        random_number = random.uniform(0,100)\n",
    "        if random_number < noise_rate:\n",
    "            train_img[i][j] = random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.9075705 ,\n",
       "       0.63868517, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.3154511 ,\n",
       "       0.35866472, 0.        , 0.        , 0.        , 0.3154807 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.41156006,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.49635807,\n",
       "       0.17632683, 0.77556837, 0.        , 0.09074488, 0.75355387,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.16551317,\n",
       "       0.        , 0.        , 0.        , 0.41249448, 0.        ,\n",
       "       0.        , 0.        , 0.9940564 , 0.        , 0.        ,\n",
       "       0.        , 0.18873668, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.95916545, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.59806734, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03817096, 0.48109403,\n",
       "       0.1530725 , 0.14686014, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.62584376, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5907641 ,\n",
       "       0.        , 0.10643008, 0.6714761 , 0.        , 0.10341699,\n",
       "       0.        , 0.        , 0.        , 0.40967   , 0.        ,\n",
       "       0.1724986 , 0.42718145, 0.        , 0.        , 0.        ,\n",
       "       0.05377351, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.2582773 , 0.10160329, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.87149984,\n",
       "       0.9061677 , 0.26847324, 0.22595397, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.4734542 , 0.        , 0.        ,\n",
       "       0.        , 0.72449416, 0.11513473, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6588783 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.12593116, 0.        ,\n",
       "       0.        , 0.        , 0.19952309, 0.        , 0.        ,\n",
       "       0.06076931, 0.        , 0.        , 0.3856076 , 0.6426317 ,\n",
       "       0.78507847, 0.09865331, 0.88417673, 0.        , 0.        ,\n",
       "       0.01622192, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.20106919, 0.        , 0.        , 0.5572987 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18314064,\n",
       "       0.67726564, 0.        , 0.5019608 , 0.5019608 , 1.        ,\n",
       "       0.24103764, 0.5019608 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.11553565, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.90741414, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.7490196 , 0.3876647 , 0.        , 0.95278436, 0.37275502,\n",
       "       0.        , 0.        , 0.80913585, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7468246 , 0.7509908 , 0.        ,\n",
       "       0.5694909 , 0.        , 0.2509804 , 0.7490196 , 0.17562269,\n",
       "       1.        , 0.2597794 , 0.59938496, 1.        , 1.        ,\n",
       "       1.        , 0.09248291, 1.        , 1.        , 0.7490196 ,\n",
       "       0.        , 0.99803233, 0.        , 0.        , 0.        ,\n",
       "       0.7975107 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.68184537, 0.        , 0.19522142, 0.        , 0.2047587 ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.28387827,\n",
       "       0.20637643, 0.40124506, 0.7490373 , 0.28101042, 0.5019608 ,\n",
       "       1.        , 1.        , 1.        , 0.09629714, 0.        ,\n",
       "       0.675007  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.50315714, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.70304006, 0.30947068, 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.5019608 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.5019608 , 1.        ,\n",
       "       1.        , 0.2509804 , 0.        , 0.        , 0.08044617,\n",
       "       0.        , 0.        , 0.        , 0.9824085 , 0.        ,\n",
       "       0.899484  , 0.        , 0.6666257 , 0.7490196 , 1.        ,\n",
       "       0.6189166 , 0.86553967, 1.        , 0.5019608 , 0.        ,\n",
       "       0.44022837, 0.6549639 , 0.555656  , 0.        , 0.        ,\n",
       "       0.2509804 , 1.        , 0.48975843, 1.        , 0.9526326 ,\n",
       "       0.922566  , 0.32840744, 0.        , 0.        , 0.68128127,\n",
       "       0.        , 0.27608946, 0.        , 0.        , 0.        ,\n",
       "       0.90360457, 1.        , 1.        , 1.        , 0.7490196 ,\n",
       "       0.00861478, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.952798  , 0.2509804 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.9940656 , 0.30216947, 1.        ,\n",
       "       1.        , 0.4372923 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.7490196 ,\n",
       "       0.21884856, 1.        , 1.        , 1.        , 0.9377003 ,\n",
       "       0.03439296, 0.7244846 , 0.7636255 , 0.9397229 , 0.        ,\n",
       "       0.17591402, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.46307772, 1.        , 1.        , 0.33278057, 0.5019608 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.2509804 ,\n",
       "       0.7490196 , 1.        , 0.467934  , 1.        , 0.48725504,\n",
       "       1.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.5976753 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.712733  , 0.        , 0.        , 1.        ,\n",
       "       0.03153036, 1.        , 1.        , 0.7490196 , 0.5019608 ,\n",
       "       0.7490196 , 0.958601  , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.7490196 , 1.        , 1.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.5388312 ,\n",
       "       0.        , 0.        , 0.28742772, 0.        , 0.        ,\n",
       "       0.        , 0.17865622, 0.453769  , 0.32873693, 1.        ,\n",
       "       0.8045448 , 1.        , 0.26076114, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.10626303, 0.        ,\n",
       "       0.        , 1.        , 1.        , 1.        , 0.2509804 ,\n",
       "       0.        , 0.        , 0.        , 0.5446948 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.2509804 , 0.7490196 , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.51900864, 1.        , 1.        , 0.683114  ,\n",
       "       0.2509804 , 0.        , 0.        , 0.        , 1.        ,\n",
       "       1.        , 1.        , 0.16432036, 0.        , 0.        ,\n",
       "       0.74662596, 0.        , 0.28097147, 0.        , 0.        ,\n",
       "       0.        , 0.38197067, 0.        , 0.        , 0.        ,\n",
       "       0.5019608 , 0.27159595, 0.5019608 , 0.5019608 , 0.5019608 ,\n",
       "       0.5019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "       0.5019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3420212 , 0.16171691, 0.28005087,\n",
       "       0.        , 0.57397217, 0.        , 0.89769495, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.95234805,\n",
       "       0.        , 0.        , 0.6629463 , 0.5905736 , 0.        ,\n",
       "       1.        , 0.0620437 , 1.        , 0.15818608, 0.        ,\n",
       "       0.08194074, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.8596421 , 0.06619497, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.16614623,\n",
       "       0.        , 0.23456322, 0.        , 0.        , 0.35671186,\n",
       "       0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "       1.        , 0.7490196 , 0.18600948, 0.64426357, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3606642 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09225903, 0.        , 0.20735985, 0.        , 0.00419006,\n",
       "       0.        , 0.        , 0.56455356, 0.        , 0.        ,\n",
       "       0.06465022, 0.7490196 , 1.        , 0.9852572 , 0.5019608 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.97309923,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07217977, 0.        , 0.80082476,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5019608 ,\n",
       "       0.35348746, 0.44308513, 0.5019608 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7608725 , 0.        , 0.        ,\n",
       "       0.        , 0.12623204, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.6018922 , 0.28535163, 0.15559426, 0.        ,\n",
       "       0.        , 0.41628098, 0.5019608 , 1.        , 1.        ,\n",
       "       0.61574405, 0.        , 0.7979213 , 0.48541486, 0.752512  ,\n",
       "       0.4934159 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.6449034 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.37764892, 0.        , 0.        , 0.36207947, 0.5867494 ,\n",
       "       0.5717676 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07569548, 1.        , 0.7845764 , 0.        ,\n",
       "       0.24200864, 0.        , 0.        , 0.7457025 , 0.        ,\n",
       "       0.        , 0.28657293, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07108606, 0.        , 0.        , 0.6014576 ,\n",
       "       0.7253059 , 0.354671  , 0.960741  , 0.        , 0.8642213 ,\n",
       "       0.        , 0.        , 0.68361956, 0.        , 0.7490196 ,\n",
       "       0.        , 0.5288712 , 0.7702786 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.9263914 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8286963 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6456585 , 0.76705396,\n",
       "       0.        , 0.28459746, 0.        , 0.        , 0.08942703,\n",
       "       0.        , 0.        , 0.04363444, 0.99870604, 0.        ,\n",
       "       0.29175255, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e)\n",
    "\n",
    "def sigmoid_dash(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def cross_entropy(y, t):\n",
    "    E = 0.0\n",
    "    for i in range(len(t[0])):\n",
    "        E = E - t[0][i]*np.log(y[0][i])\n",
    "    return E.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各レイヤで共通な機能を実装\n",
    "class Layer(object):\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self):\n",
    "        for k in self.params.keys():\n",
    "            self.params[k] = self.params[k] - self.lr * self.grads[k]\n",
    "            \n",
    "    def zerograd(self):\n",
    "        for k in self.params.keys():\n",
    "            self.grads[k] = np.zeros(shape = self.params[k].shape, dtype = self.params[k].dtype)\n",
    "            \n",
    "#順伝播、逆伝播を行う機能を実装\n",
    "class Sequential:\n",
    "    def __init__(self, layers=[]):\n",
    "        self.layers = layers\n",
    "    #レイヤの追加\n",
    "    def addlayer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    #順伝播の計算\n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "    #逆伝播の計算\n",
    "    def backward(self, y):\n",
    "        for l in reversed(self.layers):\n",
    "            y = l.backward(y)\n",
    "        return y\n",
    "    #\n",
    "    def update(self):\n",
    "        for l in self.layers:\n",
    "            l.update()\n",
    "    #勾配をゼロに\n",
    "    def zerograd(self):\n",
    "        for l in self.layers:\n",
    "            l.zerograd()\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        #正規分布に従った乱数による重みの初期化（Xivierの初期値）\n",
    "        self.params['W'] = np.random.normal(loc = 0.0, scale = np.sqrt(1.0/input_dim), size = (input_dim, output_dim)).astype(np.float32)\n",
    "        #バイアスの初期値をゼロに設定\n",
    "        self.params['b'] = np.zeros(shape = (1, output_dim), dtype = np.float32)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.params['W']) + self.params['b']\n",
    "        \n",
    "    def backward(self, y):\n",
    "        self.grads['W'] = np.dot(self.x.T, y)\n",
    "        self.grads['b'] = y\n",
    "        #print(self.grads['b'])\n",
    "        return y*self.params['W']\n",
    "    \n",
    "class SigmoidLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(SigmoidLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = sigmoid(x)\n",
    "        self.z = z\n",
    "        return z\n",
    "    \n",
    "    def backward(self, y):\n",
    "        return  np.array([np.sum(y*sigmoid_dash(self.z).T, axis=1)])     \n",
    "    \n",
    "class Classfier:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def update(self, x, t):\n",
    "        self.model.zerograd()\n",
    "        y = self.model.forward(x)\n",
    "        prob = softmax(y)\n",
    "        loss = cross_entropy(prob, t)\n",
    "        dout = prob - t\n",
    "        dout = self.model.backward(dout)\n",
    "        self.model.update()\n",
    "    \n",
    "    def test(self, x):\n",
    "        y = softmax(self.model.forward(x))\n",
    "        prob = np.array([y[0]])\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.addlayer(LinearLayer(784,1000))\n",
    "model.addlayer(SigmoidLayer())\n",
    "model.addlayer(LinearLayer(1000,10))\n",
    "classifier = Classfier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.05\n",
      "2\n",
      "0.29\n",
      "3\n",
      "0.18\n",
      "4\n",
      "0.33\n",
      "5\n",
      "0.41\n",
      "6\n",
      "0.6\n",
      "7\n",
      "0.64\n",
      "8\n",
      "0.6\n",
      "9\n",
      "0.76\n",
      "10\n",
      "0.61\n",
      "11\n",
      "0.7\n",
      "12\n",
      "0.52\n",
      "13\n",
      "0.7\n",
      "14\n",
      "0.74\n",
      "15\n",
      "0.75\n",
      "16\n",
      "0.85\n",
      "17\n",
      "0.76\n",
      "18\n",
      "0.7\n",
      "19\n",
      "0.82\n",
      "20\n",
      "0.78\n",
      "21\n",
      "0.74\n",
      "22\n",
      "0.8\n",
      "23\n",
      "0.8\n",
      "24\n",
      "0.74\n",
      "25\n",
      "0.72\n",
      "26\n",
      "0.76\n",
      "27\n",
      "0.87\n",
      "28\n",
      "0.84\n",
      "29\n",
      "0.9\n",
      "30\n",
      "0.8\n",
      "31\n",
      "0.82\n",
      "32\n",
      "0.78\n",
      "33\n",
      "0.85\n",
      "34\n",
      "0.8\n",
      "35\n",
      "0.81\n",
      "36\n",
      "0.87\n",
      "37\n",
      "0.85\n",
      "38\n",
      "0.8\n",
      "39\n",
      "0.83\n",
      "40\n",
      "0.9\n",
      "41\n",
      "0.83\n",
      "42\n",
      "0.84\n",
      "43\n",
      "0.83\n",
      "44\n",
      "0.82\n",
      "45\n",
      "0.84\n",
      "46\n",
      "0.86\n",
      "47\n",
      "0.75\n",
      "48\n",
      "0.84\n",
      "49\n",
      "0.93\n",
      "50\n",
      "0.8\n",
      "51\n",
      "0.85\n",
      "52\n",
      "0.88\n",
      "53\n",
      "0.81\n",
      "54\n",
      "0.82\n",
      "55\n",
      "0.88\n",
      "56\n",
      "0.89\n",
      "57\n",
      "0.86\n",
      "58\n",
      "0.83\n",
      "59\n",
      "0.9\n",
      "60\n",
      "0.84\n",
      "61\n",
      "0.82\n",
      "62\n",
      "0.89\n",
      "63\n",
      "0.88\n",
      "64\n",
      "0.91\n",
      "65\n",
      "0.88\n",
      "66\n",
      "0.9\n",
      "67\n",
      "0.89\n",
      "68\n",
      "0.9\n",
      "69\n",
      "0.86\n",
      "70\n",
      "0.86\n",
      "71\n",
      "0.84\n",
      "72\n",
      "0.9\n",
      "73\n",
      "0.89\n",
      "74\n",
      "0.85\n",
      "75\n",
      "0.89\n",
      "76\n",
      "0.9\n",
      "77\n",
      "0.85\n",
      "78\n",
      "0.88\n",
      "79\n",
      "0.88\n",
      "80\n",
      "0.85\n",
      "81\n",
      "0.93\n",
      "82\n",
      "0.89\n",
      "83\n",
      "0.84\n",
      "84\n",
      "0.9\n",
      "85\n",
      "0.82\n",
      "86\n",
      "0.89\n",
      "87\n",
      "0.83\n",
      "88\n",
      "0.88\n",
      "89\n",
      "0.91\n",
      "90\n",
      "0.92\n",
      "91\n",
      "0.92\n",
      "92\n",
      "0.91\n",
      "93\n",
      "0.85\n",
      "94\n",
      "0.84\n",
      "95\n",
      "0.86\n",
      "96\n",
      "0.91\n",
      "97\n",
      "0.91\n",
      "98\n",
      "0.84\n",
      "99\n",
      "0.84\n",
      "100\n",
      "0.88\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    rand1 = np.arange(60000)\n",
    "    shuffle(rand1)\n",
    "    rand2 = np.arange(10000)\n",
    "    shuffle(rand2)\n",
    "    train_img = train_img[rand1,:]\n",
    "    train_label_one_hot = train_label_one_hot[rand1,:]\n",
    "    test_img = test_img[rand2]\n",
    "    test_label_one_hot = np.array(test_label_one_hot[rand2,:])\n",
    "    for j in range(200):\n",
    "        x = np.array([train_img[j]])\n",
    "        t = np.array([train_label_one_hot[j]])\n",
    "        classifier.update(x, t)\n",
    "    count = 0\n",
    "    for j in range(100):\n",
    "        x = np.array([test_img[j]])\n",
    "        prob = classifier.test(x)\n",
    "        if np.argmax(prob[0]) == np.argmax(test_label_one_hot[j]):\n",
    "            count += 1\n",
    "    print(i+1)\n",
    "    print(count/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
