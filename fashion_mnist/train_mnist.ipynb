{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import *\n",
    "from utils import mnist_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像の読み込み\n",
    "train_img, train_label = mnist_reader.load_mnist('data', kind='train')\n",
    "test_img, test_label = mnist_reader.load_mnist('data', kind='t10k')\n",
    "#画素値を0~1の間の値に変換\n",
    "train_img = train_img / 255\n",
    "test_img = test_img / 255\n",
    "train_img = train_img.astype(np.float32)\n",
    "#ラベルをone-hot表現で表す\n",
    "rain_label = [int(x) for x in train_label]\n",
    "train_label_one_hot = np.identity(10)[train_label].astype(np.float32)\n",
    "test_label = [int(x) for x in test_label]\n",
    "test_label_one_hot = np.identity(10)[test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e)\n",
    "\n",
    "def sigmoid_dash(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def cross_entropy(y, t):\n",
    "    E = 0.0\n",
    "    for i in range(len(t[0])):\n",
    "        E = E - t[0][i]*np.log(y[0][i])\n",
    "    return E.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各レイヤで共通な機能を実装\n",
    "class Layer(object):\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.params = {}\n",
    "        self.grads = {}\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self):\n",
    "        for k in self.params.keys():\n",
    "            self.params[k] = self.params[k] - self.lr * self.grads[k]\n",
    "            \n",
    "    def zerograd(self):\n",
    "        for k in self.params.keys():\n",
    "            self.grads[k] = np.zeros(shape = self.params[k].shape, dtype = self.params[k].dtype)\n",
    "            \n",
    "    def debug(self):\n",
    "        for k in self.params.keys():\n",
    "            print(self.params[k])\n",
    "            \n",
    "#順伝播、逆伝播を行う機能を実装\n",
    "class Sequential:\n",
    "    def __init__(self, layers=[]):\n",
    "        self.layers = layers\n",
    "    #レイヤの追加\n",
    "    def addlayer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    #順伝播の計算\n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "    #逆伝播の計算\n",
    "    def backward(self, y):\n",
    "        for l in reversed(self.layers):\n",
    "            y = l.backward(y)\n",
    "        return y\n",
    "    #\n",
    "    def update(self):\n",
    "        for l in self.layers:\n",
    "            l.update()\n",
    "    #勾配をゼロに\n",
    "    def zerograd(self):\n",
    "        for l in self.layers:\n",
    "            l.zerograd()\n",
    "            \n",
    "    def debug(self):\n",
    "        for l in self.layers:\n",
    "            l.debug()\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        #正規分布に従った乱数による重みの初期化（Xivierの初期値）\n",
    "        self.params['W'] = np.random.normal(loc = 0.0, scale = np.sqrt(1.0/input_dim), size = (input_dim, output_dim)).astype(np.float32)\n",
    "        #バイアスの初期値をゼロに設定\n",
    "        self.params['b'] = np.zeros(shape = (1, output_dim), dtype = np.float32)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.params['W']) + self.params['b']\n",
    "        \n",
    "    def backward(self, y):\n",
    "        self.grads['W'] = np.dot(self.x.T, y)\n",
    "        self.grads['b'] = y\n",
    "        #print(self.grads['b'])\n",
    "        return y*self.params['W']\n",
    "    \n",
    "class SigmoidLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(SigmoidLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = sigmoid(x)\n",
    "        self.z = z\n",
    "        return z\n",
    "    \n",
    "    def backward(self, y):\n",
    "        return  np.array([np.sum(y*sigmoid_dash(self.z).T, axis=1)])\n",
    "    \n",
    "class Classfier:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def update(self, x, t):\n",
    "        self.model.zerograd()\n",
    "        y = self.model.forward(x)\n",
    "        prob = softmax(y)\n",
    "        loss = cross_entropy(prob, t)\n",
    "        dout = prob - t\n",
    "        dout = self.model.backward(dout)\n",
    "        self.model.update()\n",
    "    \n",
    "    def test(self, x):\n",
    "        y = softmax(self.model.forward(x))\n",
    "        prob = np.array([y[0]])\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.addlayer(LinearLayer(784,2000))\n",
    "model.addlayer(SigmoidLayer())\n",
    "model.addlayer(LinearLayer(2000,500))\n",
    "model.addlayer(SigmoidLayer())\n",
    "model.addlayer(LinearLayer(500,10))\n",
    "classifier = Classfier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.09\n",
      "2\n",
      "0.11\n",
      "3\n",
      "0.1\n",
      "4\n",
      "0.16\n",
      "5\n",
      "0.23\n",
      "6\n",
      "0.39\n",
      "7\n",
      "0.25\n",
      "8\n",
      "0.3\n",
      "9\n",
      "0.4\n",
      "10\n",
      "0.38\n",
      "11\n",
      "0.39\n",
      "12\n",
      "0.56\n",
      "13\n",
      "0.44\n",
      "14\n",
      "0.51\n",
      "15\n",
      "0.42\n",
      "16\n",
      "0.56\n",
      "17\n",
      "0.48\n",
      "18\n",
      "0.47\n",
      "19\n",
      "0.63\n",
      "20\n",
      "0.59\n",
      "21\n",
      "0.46\n",
      "22\n",
      "0.55\n",
      "23\n",
      "0.71\n",
      "24\n",
      "0.7\n",
      "25\n",
      "0.66\n",
      "26\n",
      "0.66\n",
      "27\n",
      "0.62\n",
      "28\n",
      "0.55\n",
      "29\n",
      "0.7\n",
      "30\n",
      "0.68\n",
      "31\n",
      "0.59\n",
      "32\n",
      "0.65\n",
      "33\n",
      "0.64\n",
      "34\n",
      "0.71\n",
      "35\n",
      "0.61\n",
      "36\n",
      "0.6\n",
      "37\n",
      "0.64\n",
      "38\n",
      "0.77\n",
      "39\n",
      "0.64\n",
      "40\n",
      "0.63\n",
      "41\n",
      "0.63\n",
      "42\n",
      "0.67\n",
      "43\n",
      "0.73\n",
      "44\n",
      "0.64\n",
      "45\n",
      "0.72\n",
      "46\n",
      "0.65\n",
      "47\n",
      "0.66\n",
      "48\n",
      "0.74\n",
      "49\n",
      "0.7\n",
      "50\n",
      "0.75\n",
      "51\n",
      "0.66\n",
      "52\n",
      "0.67\n",
      "53\n",
      "0.65\n",
      "54\n",
      "0.66\n",
      "55\n",
      "0.59\n",
      "56\n",
      "0.78\n",
      "57\n",
      "0.75\n",
      "58\n",
      "0.69\n",
      "59\n",
      "0.65\n",
      "60\n",
      "0.65\n",
      "61\n",
      "0.75\n",
      "62\n",
      "0.75\n",
      "63\n",
      "0.68\n",
      "64\n",
      "0.7\n",
      "65\n",
      "0.69\n",
      "66\n",
      "0.77\n",
      "67\n",
      "0.75\n",
      "68\n",
      "0.69\n",
      "69\n",
      "0.81\n",
      "70\n",
      "0.77\n",
      "71\n",
      "0.64\n",
      "72\n",
      "0.74\n",
      "73\n",
      "0.6\n",
      "74\n",
      "0.66\n",
      "75\n",
      "0.75\n",
      "76\n",
      "0.67\n",
      "77\n",
      "0.75\n",
      "78\n",
      "0.75\n",
      "79\n",
      "0.7\n",
      "80\n",
      "0.7\n",
      "81\n",
      "0.71\n",
      "82\n",
      "0.75\n",
      "83\n",
      "0.71\n",
      "84\n",
      "0.76\n",
      "85\n",
      "0.72\n",
      "86\n",
      "0.67\n",
      "87\n",
      "0.72\n",
      "88\n",
      "0.69\n",
      "89\n",
      "0.68\n",
      "90\n",
      "0.65\n",
      "91\n",
      "0.66\n",
      "92\n",
      "0.76\n",
      "93\n",
      "0.67\n",
      "94\n",
      "0.81\n",
      "95\n",
      "0.75\n",
      "96\n",
      "0.76\n",
      "97\n",
      "0.78\n",
      "98\n",
      "0.76\n",
      "99\n",
      "0.68\n",
      "100\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    rand1 = np.arange(60000)\n",
    "    shuffle(rand1)\n",
    "    rand2 = np.arange(10000)\n",
    "    shuffle(rand2)\n",
    "    train_img = train_img[rand1,:]\n",
    "    train_label_one_hot = train_label_one_hot[rand1,:]\n",
    "    test_img = test_img[rand2]\n",
    "    test_label_one_hot = np.array(test_label_one_hot[rand2,:])\n",
    "    for j in range(200):\n",
    "        x = np.array([train_img[j]])\n",
    "        t = np.array([train_label_one_hot[j]])\n",
    "        classifier.update(x, t)\n",
    "    count = 0\n",
    "    for j in range(100):\n",
    "        x = np.array([test_img[j]])\n",
    "        prob = classifier.test(x)\n",
    "        if np.argmax(prob[0]) == np.argmax(test_label_one_hot[j]):\n",
    "            count += 1\n",
    "    print(i+1)\n",
    "    print(count/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
